{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Students:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Get the webpage content by using functions in \n",
    "__[urllib module](https://docs.python.org/3/library/urllib.html#module-urllib)__.\n",
    "\n",
    "Other libraries are also fine to achieve the crawling.\n",
    "\n",
    "e.g. scrapy, beautifulsoup... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "\n",
    "\n",
    "x = urllib.request.urlopen('https://play.google.com/store/apps/category/GAME?hl=en').read().decode('utf-8')\n",
    "#print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/store/apps/category/GAME_ACTION', '/store/apps/category/GAME_ADVENTURE', '/store/apps/category/GAME_ARCADE', '/store/apps/category/GAME_BOARD', '/store/apps/category/GAME_CARD', '/store/apps/category/GAME_CASINO', '/store/apps/category/GAME_CASUAL', '/store/apps/category/GAME_EDUCATIONAL', '/store/apps/category/GAME_MUSIC', '/store/apps/category/GAME_PUZZLE', '/store/apps/category/GAME_RACING', '/store/apps/category/GAME_ROLE_PLAYING', '/store/apps/category/GAME_SIMULATION', '/store/apps/category/GAME_SPORTS', '/store/apps/category/GAME_STRATEGY', '/store/apps/category/GAME_TRIVIA', '/store/apps/category/GAME_WORD', '/store/apps/category/GAME_ACTION', '/store/apps/category/GAME_ADVENTURE', '/store/apps/category/GAME_ARCADE', '/store/apps/category/GAME_BOARD', '/store/apps/category/GAME_CARD', '/store/apps/category/GAME_CASINO', '/store/apps/category/GAME_CASUAL', '/store/apps/category/GAME_EDUCATIONAL', '/store/apps/category/GAME_MUSIC', '/store/apps/category/GAME_PUZZLE', '/store/apps/category/GAME_RACING', '/store/apps/category/GAME_ROLE_PLAYING', '/store/apps/category/GAME_SIMULATION', '/store/apps/category/GAME_SPORTS', '/store/apps/category/GAME_STRATEGY', '/store/apps/category/GAME_TRIVIA', '/store/apps/category/GAME_WORD']\n"
     ]
    }
   ],
   "source": [
    "appreg = r'href=\\\"(/store/apps/details.*?)\\\"'\n",
    "appre = re.compile(appreg)\n",
    "app_url_list = re.findall(appre,x)\n",
    "\n",
    "\n",
    "reg1 = r'href=\\\"(/store/apps/category/GAME_.*?)\\\"'\n",
    "cat_re = re.compile(reg1)\n",
    "cat_url_list = re.findall(cat_re,x)\n",
    "print(cat_url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Get app url by regular expression using functions from __[re module](https://docs.python.org/3/library/re.html?highlight=re#module-re)__.\n",
    "\n",
    "A useful online regular expression check.\n",
    "__[Check your regular expression first](https://regex101.com)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1699\n",
      "['/store/apps/details?id=com.highway.motorrider', '/store/apps/details?id=com.ninjakiwi.bloonstd6', '/store/apps/details?id=com.gsn.android.tripeaks', '/store/apps/details?id=com.Heyworks.PocketTroopsVK', '/store/apps/details?id=com.warducks.smooshymushy', '/store/apps/details?id=com.dmi.nascarheat', '/store/apps/details?id=com.NinJaGo.Shadow', '/store/apps/details?id=com.tndh.cutepuppycare', '/store/apps/details?id=com.cg.real.car.hill.racing.games', '/store/apps/details?id=mobi.square.sr.android']\n"
     ]
    }
   ],
   "source": [
    "start = 'https://play.google.com'\n",
    "url_ending = '/collection/topselling_new_free?hl=en'\n",
    "url_ending2 = '/collection/topgrossing?hl=en'\n",
    "for e in cat_url_list:\n",
    "    x = urllib.request.urlopen(start+e+url_ending).read().decode('utf-8')\n",
    "    app_url_list += re.findall(appre,x)\n",
    "    x = urllib.request.urlopen(start+e+url_ending2).read().decode('utf-8')\n",
    "    app_url_list += re.findall(appre,x)\n",
    "app_url_list = list(set(app_url_list))\n",
    "print(len(app_url_list))\n",
    "print(app_url_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Access specific webpage to get description of each app and then store the description in files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemprop=\"description\"><content>What’s New:<br>♠ Coming soon: a whole NEW WORLD! Come explore Tiki Paradise and test your skills in a new kind of gameplay. Hint: two cards are better than one!<br>♠ Bug fixes: As always, if you spot a glitch, drop us a line and we’ll look into it.</content><div jsname=\"WgKync\" class=\"uwAgLc\"></div>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "desc_re = r'itemprop=\\\"description.*?\\\">.*?<div jsname=\\\".*?\\\">.*?</div>'\n",
    "desc_reg = re.compile(desc_re)\n",
    "descriptions = []\n",
    "\n",
    "for url_ in app_url_list:\n",
    "    x = urllib.request.urlopen(start+url_+'&hl=en').read().decode('utf-8')\n",
    "    descriptions += re.findall(desc_reg,x)\n",
    "print(descriptions[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXCLUSIVE RELEASES: 918 Spyder MARTINI RACING, Cayman GT4 ‘Salzburg’ In honour of Porsche’s iconic history, CSR2 brings you the Cayman GT4 ‘Salzburg’ and the 918 Spyder MARTINI RACING.   NEW EVENTS: Porsche 70th Anniversary Finale, Halloween CSR2 are bringing you a finale to remember for Porsche&#39;s 70th anniversary and a spooky Halloween treat.  NEW CARS: Porsche, Mercedes, Chevrolet Four new cars available for the first time in a game and eight other ones for your collection!\n"
     ]
    }
   ],
   "source": [
    "get_text_re = r'(?<=\\<content\\>)(.*)(?=\\</content)'\n",
    "get_text_reg = re.compile(get_text_re)\n",
    "desc_texts = []\n",
    "for desc in descriptions:\n",
    "    tmp = re.findall(get_text_re,desc)\n",
    "    if tmp != []:\n",
    "        text = tmp[0].replace('<br>',' ')\n",
    "        desc_texts += [text]\n",
    "        \n",
    "print(desc_texts[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save('descriptions',desc_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_texts = np.load('descriptions.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Inverted file index (Vector Model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Preprocess text using NLP techniques from __[nltk module](http://www.nltk.org/py-modindex.html)__ or spaCy.\n",
    "\n",
    "Using nltk.download(ID) to get the corpora if it is not downloaded before. __[nltk corpora](http://www.nltk.org/nltk_data/)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/johmy592/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclusive releases 918 spyder martini racing cayman gt4 salzburg in honour of porsches iconic history csr2 brings you the cayman gt4 salzburg and the 918 spyder martini racing   new events porsche 70th anniversary finale halloween csr2 are bringing you a finale to remember for porsches 70th anniversary and a spooky halloween treat  new cars porsche mercedes chevrolet four new cars available for the first time in a game and eight other ones for your collection\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "for i in range(len(desc_texts)):\n",
    "    desc_texts[i] = ''.join(ch.lower() for ch in desc_texts[i] if ch.isalnum() or ch==' ')\n",
    "    desc_texts[i] = desc_texts[i].replace('39','\\'')\n",
    "    \n",
    "print(desc_texts[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['update', 'includes', 'improvement', 'provide', 'better', 'gaming', 'experience', 'constantly', 'strive', 'make', 'game', 'better', 'feedback', 'always', 'welcome', 'thank', 'playing', 'archery', 'king']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "tokens = [word_tokenize(t) for t in desc_texts]\n",
    "tokens = [[wnl.lemmatize(t) for t in d if t not in stopwords.words('english')] for d in tokens]\n",
    "print(tokens[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...)Compute tdidf \n",
    "eg. Using functions from __[scikit-learn module](http://scikit-learn.org/stable/modules/classes.html)__. TfidfVectorizer is used for converting a collection of raw documents to a matrix of TF-IDF features.\n",
    "#### You can also build the tfidf matrix with other library or your own algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]\n",
      " [0.         0.27925389 0.         0.22830836 0.         0.87501037\n",
      "  0.22830836 0.         0.22830836]\n",
      " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]\n",
      " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n",
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "transvector = TfidfVectorizer()\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This is the second second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',]\n",
    "tfidf1 = transvector.fit_transform(corpus)\n",
    "print(tfidf1.toarray())\n",
    "print(transvector.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4836)\t0.16491941725871823\n",
      "  (0, 3218)\t0.20604277934852913\n",
      "  (0, 1836)\t0.14753068686829068\n",
      "  (0, 3135)\t0.18709126624900868\n",
      "  (0, 548)\t0.18709126624900868\n",
      "  (0, 4177)\t0.16491941725871823\n",
      "  (0, 1280)\t0.1311047761741568\n",
      "  (0, 1607)\t0.18099024174164716\n",
      "  (0, 3548)\t0.1949568548533839\n",
      "  (0, 1959)\t0.31363936703741074\n",
      "  (0, 4624)\t0.17600534175386343\n",
      "  (0, 2660)\t0.20604277934852913\n",
      "  (0, 1178)\t0.20604277934852913\n",
      "  (0, 4311)\t0.18099024174164716\n",
      "  (0, 2668)\t0.1949568548533839\n",
      "  (0, 795)\t0.1949568548533839\n",
      "  (0, 2319)\t0.20604277934852913\n",
      "  (0, 3517)\t0.18709126624900868\n",
      "  (0, 3118)\t0.20604277934852913\n",
      "  (0, 4315)\t0.20604277934852913\n",
      "  (0, 3730)\t0.20604277934852913\n",
      "  (0, 1957)\t0.12290985484435454\n",
      "  (0, 4921)\t0.14753068686829068\n",
      "  (0, 3538)\t0.20604277934852913\n",
      "  (0, 2617)\t0.10768775123670149\n",
      "  :\t:\n",
      "  (1377, 431)\t0.11422626953866727\n",
      "  (1377, 2172)\t0.13409704851216245\n",
      "  (1377, 4266)\t0.1521251228230917\n",
      "  (1377, 3663)\t0.12130592622723502\n",
      "  (1377, 3577)\t0.12592202983669498\n",
      "  (1377, 4221)\t0.2862221713352541\n",
      "  (1377, 2888)\t0.11422626953866727\n",
      "  (1377, 771)\t0.10149839438330202\n",
      "  (1377, 1216)\t0.12963586783659561\n",
      "  (1377, 4319)\t0.1585206839655554\n",
      "  (1377, 1853)\t0.1521251228230917\n",
      "  (1377, 3132)\t0.14716434020006008\n",
      "  (1377, 945)\t0.3170413679311108\n",
      "  (1377, 505)\t0.1585206839655554\n",
      "  (1377, 5128)\t0.16753472112102002\n",
      "  (1377, 5127)\t0.16753472112102002\n",
      "  (1377, 5126)\t0.16753472112102002\n",
      "  (1377, 5125)\t0.16753472112102002\n",
      "  (1377, 5124)\t0.16753472112102002\n",
      "  (1377, 5123)\t0.16753472112102002\n",
      "  (1377, 5158)\t0.16753472112102002\n",
      "  (1377, 4124)\t0.16753472112102002\n",
      "  (1377, 5122)\t0.16753472112102002\n",
      "  (1377, 994)\t0.16753472112102002\n",
      "  (1377, 3888)\t0.16753472112102002\n"
     ]
    }
   ],
   "source": [
    "transvector = TfidfVectorizer(preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
    "tfidf1 = transvector.fit_transform(tokens)\n",
    "print(tfidf1)\n",
    "#print(tfidf1.toarray())\n",
    "#print(transvector.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sp\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5563 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 28 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Process\n",
    "\n",
    "eg. \"Dragon, Control, hero, running\"\n",
    "\n",
    "eg. \"The hero controls the dragon to run.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4305)\t0.7328705696650658\n",
      "  (0, 2244)\t0.6803680828190003\n",
      "287\n",
      "0.41638954255743044\n"
     ]
    }
   ],
   "source": [
    "test_search = \"shoot guns ¥{[]}\"\n",
    "\n",
    "def preprocess_search(search_term):\n",
    "    tolower = ''.join(ch.lower() for ch in search_term if ch.isalnum() or ch==' ')\n",
    "    tok = word_tokenize(tolower) \n",
    "    return [wnl.lemmatize(t) for t in tok if t not in stopwords.words('english')]\n",
    "    \n",
    "real_search = preprocess_search(test_search)\n",
    "search_vec = transvector.transform([real_search])\n",
    "print(search_vec)\n",
    "\n",
    "similarities = tfidf1.dot(search_vec.transpose())\n",
    "print(np.argmax(similarities))\n",
    "print(np.amax(similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119\n",
      "(1378, 1)\n",
      "(1378,)\n",
      "[1119  726  800  166  685]\n",
      "the all new video poker app is here to keep your video poker itch scratched for hours get up to 8x the winnings in multistrike poker play up to 25 hands at once in multiplay poker or stick to the tried and true classics if you love video poker youll love pechangas best bet video poker\n",
      "############################################ \n",
      "\n",
      "jump in for the best poker experience ever mega hit poker is rng ready certified by itech labs  whats new  bug fixes amp game optimization\n",
      "############################################ \n",
      "\n",
      "the new world poker club version is out weve tuned up the speed and stability of the app as well as added some gifts and updated the special promos which now offer even more deals and bargains dont forget to check out the new events too the clatter of chips the clinking of coins and the rustle of cards are all music to the ears of any devout poker fan  cant wait for you to join us at the tables place your bets ladies and gentlemen\n",
      "############################################ \n",
      "\n",
      "heads up club vegas spinners brand new update is on its way this update includes  new video pokers are coming soon  minor bug fixes and graphic improvements good luck amp have fun\n",
      "############################################ \n",
      "\n",
      "we have a great new governor of poker 3 update for you  private chat with friends  new christmas events  new hats for christmas  lag amp frame drops fixed  lots of tiny bugfixes\n",
      "############################################ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_top_results(search_term,k):\n",
    "    real_search = preprocess_search(search_term)\n",
    "    search_vec = transvector.transform([real_search])\n",
    "    similarities = tfidf1.dot(search_vec.transpose())\n",
    "    print(np.argmax(similarities.todense()))\n",
    "    print(np.shape(similarities.toarray()))\n",
    "    print(np.shape(similarities.toarray()[:,0]))\n",
    "    return np.argsort(similarities.toarray()[:,0])[-k:][::-1]\n",
    "     \n",
    "results = get_top_results('poker omaha',5)\n",
    "print(results)\n",
    "for i in results:\n",
    "    print(desc_texts[i])\n",
    "    print('############################################','\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
